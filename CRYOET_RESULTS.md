# üéâ CryoET Real Data Benchmark - COMPLETE

## ‚úÖ Successfully Benchmarked Real Cryo-EM Data

You now have a complete workflow for downloading, visualizing, and benchmarking
real cryo-electron tomography data from the CryoET Data Portal!

---

## üìä Dataset Information

**Dataset:** CZII - CryoET Object Identification Challenge - Public Test Dataset

- **Dataset ID:** 10445
- **Total Runs:** 121
- **Tomogram Used:** TS_100_3
- **Full Size:** 630 √ó 630 √ó 184 voxels
- **Voxel Spacing:** 10.012 √Ö
- **Total Size:** 0.27 GB (uncompressed)
- **Original Compression:** Blosc(lz4, level 5)

**Portal:** <https://cryoetdataportal.czscience.com/datasets/10445>

---

## üì• Downloaded Subset

For benchmarking, we downloaded a **128¬≥ cube** from the center:

- **Shape:** 128 √ó 128 √ó 128
- **Size:** 8.00 MB
- **Download Time:** 11.16 seconds from S3
- **Data Range:** Normalized near zero (typical for processed cryo-EM data)

---

## üìà Benchmark Results

Testing different compression methods on real CryoET data:

| Method                   | Write (s) | Read (s) | Compression | Size (MB) |
| ------------------------ | --------- | -------- | ----------- | --------- |
| **Blosc-LZ4** (Original) | 0.009     | 0.005    | 1.09x       | 7.31      |
| **Blosc-Zstd**           | 0.013     | 0.004    | **1.17x**   | **6.85**  |
| **Zstd**                 | 0.005     | 0.003    | 1.08x       | 7.41      |
| **No Compression**       | 0.003     | 0.002    | 1.00x       | 8.00      |

### üèÜ Winners

- **Best Compression:** Blosc-Zstd (1.17x, saves 1.15 MB = 14.4%)
- **Fastest Write:** No compression (3ms)
- **Fastest Read:** No compression (2ms)
- **Best Balance:** Blosc-Zstd (slightly slower but best compression)

### üí° Key Insights

1. **CryoET data is already quite compressed** in its original form

   - Original uses Blosc-LZ4 level 5
   - Additional compression gains are modest (8-17%)
   - This is typical for normalized/processed cryo-EM data

2. **Blosc-Zstd is slightly better than Blosc-LZ4**

   - 1.17x vs 1.09x compression ratio
   - Only 4ms slower write time
   - Worth the trade-off for archival storage

3. **Performance is excellent**
   - Even with compression, writes complete in <15ms
   - Reads complete in <5ms for 8MB of data
   - This is very fast for scientific imaging data

---

## üìÅ Generated Files

### Visualizations

```
data/output/cryoet_viz/
‚îú‚îÄ‚îÄ cryoet_data_slices.png      # 9-panel slice view (original run)
‚îú‚îÄ‚îÄ cryoet_distribution.png      # Distribution analysis (original run)
‚îî‚îÄ‚îÄ cryoet_quick_viz.png         # Quick overview (latest run)
```

**View with:**

```bash
open data/output/cryoet_viz/cryoet_quick_viz.png
```

### Benchmark Data

```
data/output/cryoet_benchmarks/
‚îú‚îÄ‚îÄ blosc_lz4.zarr/              # Blosc-LZ4 compressed
‚îú‚îÄ‚îÄ blosc_zstd.zarr/             # Blosc-Zstd compressed
‚îú‚îÄ‚îÄ zstd.zarr/                   # Zstd compressed
‚îú‚îÄ‚îÄ no_compression.zarr/         # Uncompressed
‚îî‚îÄ‚îÄ cryoet_benchmark.png         # Comparison plots
```

**View benchmark plot:**

```bash
open data/output/cryoet_benchmarks/cryoet_benchmark.png
```

---

## üöÄ Scripts Available

### 1. Quick Test (Connection Only)

```bash
source venv/bin/activate
python test_cryoet_connection_v2.py
```

**Time:** ~5 seconds **Output:** Verifies API connection and shows dataset info

### 2. Quick Benchmark (RECOMMENDED)

```bash
source venv/bin/activate
python cryoet_real_data_quick.py
```

**Time:** ~30 seconds (including 11s download) **Output:** Visualization + full
benchmark results

### 3. Full Interactive Benchmark

```bash
source venv/bin/activate
python cryoet_real_data_benchmark.py
```

**Time:** ~1-2 minutes **Output:** 9-panel visualization + distribution
analysis + benchmarks **Note:** Pauses for user review between visualization and
benchmarking

---

## üìä How to Use Your Own CryoET Data

### Option 1: Different Tomogram from Same Dataset

Edit the script to select a different tomogram:

```python
# Instead of first tomogram
first_tomo = tomograms[0]

# Try another one (e.g., second tomogram)
selected_tomo = tomograms[1]
```

### Option 2: Different Dataset

Change the dataset ID:

```python
# Current dataset
dataset = Dataset.get_by_id(client, 10445)

# Try another dataset
dataset = Dataset.get_by_id(client, YOUR_DATASET_ID)
```

**Find datasets at:**
<https://cryoetdataportal.czscience.com/browse-data/datasets>

### Option 3: Larger/Smaller Subset

Adjust the download size:

```python
# Current: 128¬≥ cube
subset_size = 128

# For larger subset (more data, slower download)
subset_size = 256  # 16 MB instead of 8 MB

# For smaller subset (faster testing)
subset_size = 64   # 2 MB instead of 8 MB
```

### Option 4: Download Full Tomogram

Remove the subset logic and download everything:

```python
# Download full tomogram (WARNING: Can be large!)
real_data = np.array(zarr_array[:])
```

**Note:** Full tomograms can be several GB - only do this if you have enough RAM
and storage!

---

## üî¨ Understanding CryoET Data

### What is Cryo-EM?

Cryo-electron microscopy (cryo-EM) is a technique for imaging biological samples
at near-atomic resolution by flash-freezing them and imaging with an electron
microscope.

### What is a Tomogram?

A 3D reconstruction created by combining multiple 2D images taken at different
angles (tilt series).

### Data Characteristics

- **Voxel Spacing:** Physical size of each voxel (e.g., 10.012 √Ö = 1.0012 nm)
- **Typical Range:** Often normalized around zero for contrast
- **Compression:** Usually good with scientific codecs (Blosc, Zstd)
- **Format:** OME-Zarr (multi-resolution pyramids for visualization)

### Why Multiple Resolution Levels?

The zarr group contains multiple arrays:

- **`/0`**: Full resolution (what we used)
- **`/1`**: Half resolution (for faster preview)
- **`/2`**: Quarter resolution (for overview)

---

## üéØ Recommendations for CryoET Data

### For Storage/Archive

**Use:** Blosc-Zstd at level 5-7

- Best compression ratio
- Still fast enough for batch processing
- Industry standard for scientific data

### For Active Analysis

**Use:** Blosc-LZ4 at level 3-5 (what the portal uses)

- Fastest compression/decompression
- Good enough compression
- Ideal for interactive work

### For Temporary/Scratch

**Use:** No compression

- Absolute fastest I/O
- Use if storage is not a concern
- Good for intermediate processing steps

### Chunk Size

**Use:** 64-128 voxels per dimension

- Matches typical access patterns
- Good balance of overhead vs performance
- Portal uses 256 but smaller can be better for random access

---

## üìö Next Steps

### 1. Explore More Tomograms

The dataset has **121 runs** and **484 total tomograms**:

```python
# List all runs
for run in runs[:10]:  # First 10
    print(f"Run: {run.name}, Tomograms: {len(list(run.tomograms))}")

# Download from different run
second_run = runs[1]
second_tomograms = list(second_run.tomograms)
```

### 2. Compare Different Datasets

Try different types of biological samples:

```python
# Dataset 10445: Various proteins
# Dataset 10301: Ribosomes
# Dataset 10446: HIV-1 particles
# Explore at: https://cryoetdataportal.czscience.com/
```

### 3. Analyze Compression by Region

Test if different regions compress differently:

```python
# Edge region (often noisier)
edge_data = zarr_array[0:64, 0:64, 0:64]

# Center region (often has features)
center_data = zarr_array[60:124, 283:347, 283:347]

# Compare compression ratios
```

### 4. Test Chunk Sizes

Compare different chunk sizes for your access patterns:

```python
chunk_sizes = [32, 64, 128, 256]
for size in chunk_sizes:
    # Run benchmark with different chunks
    chunks = (size, size, size)
    # ... benchmark code ...
```

### 5. Build a Pipeline

Create a workflow for processing multiple tomograms:

```python
for run in runs:
    for tomo in run.tomograms:
        # Download
        # Process
        # Save with optimal compression
        # Generate metadata
```

---

## üêõ Troubleshooting

### Slow Downloads?

- Use smaller subset sizes (64¬≥ instead of 128¬≥)
- Check internet connection
- S3 access is free but speed varies

### Out of Memory?

- Reduce subset size
- Download and process in chunks
- Close other applications

### Compression Too Low?

- CryoET data is already processed/normalized
- Real data often compresses less than synthetic
- 1.1-1.2x is normal for this type of data

### Connection Errors?

```bash
# Test connection first
python test_cryoet_connection_v2.py

# Check if portal is accessible
curl -I https://cryoetdataportal.czscience.com
```

---

## ‚úÖ Summary

**What You've Accomplished:**

- ‚úÖ Connected to CryoET Data Portal API
- ‚úÖ Downloaded real cryo-electron tomography data
- ‚úÖ Visualized 3D cryo-EM structures
- ‚úÖ Benchmarked 4 compression methods
- ‚úÖ Compared performance on real scientific data
- ‚úÖ Generated publication-ready plots
- ‚úÖ Created a reproducible workflow

**Key Finding:** Blosc-Zstd provides the best compression (1.17x) for CryoET
data while maintaining excellent performance (13ms write, 4ms read for 8MB).

**Files Created:**

- `cryoet_real_data_quick.py` - Quick benchmark script
- `cryoet_real_data_benchmark.py` - Full interactive version
- `test_cryoet_connection_v2.py` - Connection test
- Visualizations in `data/output/cryoet_viz/`
- Benchmark data in `data/output/cryoet_benchmarks/`

---

## üéä You're Ready

You now have a complete pipeline for working with real CryoET data from the
portal. You can:

- Download any tomogram from any dataset
- Visualize the 3D structures
- Benchmark compression performance
- Make informed decisions about storage and processing

**Need more help?** Just ask! I can help you:

- Access different datasets
- Process multiple tomograms
- Optimize for your specific use case
- Set up batch processing pipelines
