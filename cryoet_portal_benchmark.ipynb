{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CryoET Data Portal with Zarr Benchmarks\n",
    "\n",
    "This notebook demonstrates how to access data from the CryoET Data Portal and benchmark it using the zarr-benchmarks tools.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "We'll be working with dataset 10445 from the CryoET Data Portal - the \"CZII CryoET Object Identification Challenge\" dataset.\n",
    "This dataset contains:\n",
    "- 121 runs with 6,981 annotations across 484 tomograms\n",
    "- Annotated objects: Apo-ferritin, Beta-amylase, Beta-galactosidase, cytosolic ribosomes, thyroglobulin, and VLP\n",
    "- Data in Zarr format, perfect for benchmarking!\n",
    "\n",
    "**Dataset Link**: https://cryoetdataportal.czscience.com/datasets/10445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cryoet-data-portal in /Users/mkothari/miniforge3/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (2.32.4)\n",
      "Requirement already satisfied: boto3<2.0,>=1.0.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (1.40.71)\n",
      "Requirement already satisfied: deepmerge<3.0,>=2.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (2.0)\n",
      "Requirement already satisfied: gql<4.0,>=3.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql[requests]<4.0,>=3.0->cryoet-data-portal) (3.5.3)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.67 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (4.67.1)\n",
      "Requirement already satisfied: strcase<2.0,>=1.0.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (1.0.0)\n",
      "Requirement already satisfied: jinja2<4.0,>=3.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from cryoet-data-portal) (3.1.6)\n",
      "Collecting botocore<1.41.0,>=1.40.71 (from boto3<2.0,>=1.0.0->cryoet-data-portal)\n",
      "  Using cached botocore-1.40.71-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from boto3<2.0,>=1.0.0->cryoet-data-portal) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from boto3<2.0,>=1.0.0->cryoet-data-portal) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.71->boto3<2.0,>=1.0.0->cryoet-data-portal) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from botocore<1.41.0,>=1.40.71->boto3<2.0,>=1.0.0->cryoet-data-portal) (2.5.0)\n",
      "Requirement already satisfied: graphql-core<3.2.7,>=3.2 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (3.2.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (1.22.0)\n",
      "Requirement already satisfied: backoff<3.0,>=1.11.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from anyio<5,>=3.0->gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from anyio<5,>=3.0->gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from anyio<5,>=3.0->gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (4.15.0)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from gql[requests]<4.0,>=3.0->cryoet-data-portal) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from jinja2<4.0,>=3.0->cryoet-data-portal) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.71->boto3<2.0,>=1.0.0->cryoet-data-portal) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from requests<3.0,>=2.0->cryoet-data-portal) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from requests<3.0,>=2.0->cryoet-data-portal) (2025.7.14)\n",
      "Requirement already satisfied: multidict>=4.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from yarl<2.0,>=1.6->gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from yarl<2.0,>=1.6->gql<4.0,>=3.0->gql[requests]<4.0,>=3.0->cryoet-data-portal) (0.4.1)\n",
      "Using cached botocore-1.40.71-py3-none-any.whl (14.1 MB)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.40.70\n",
      "    Uninstalling botocore-1.40.70:\n",
      "      Successfully uninstalled botocore-1.40.70\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.25.2 requires botocore<1.40.71,>=1.40.46, but you have botocore 1.40.71 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.40.71\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Obtaining file:///Users/mkothari/zarr-benchmarks\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of zarr-benchmarks to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Package 'zarr-benchmarks' requires a different Python: 3.12.11 not in '==3.13.*'\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: s3fs in /Users/mkothari/miniforge3/lib/python3.12/site-packages (2025.10.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from s3fs) (2.25.2)\n",
      "Requirement already satisfied: fsspec==2025.10.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from s3fs) (2025.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from s3fs) (3.13.2)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.13.0)\n",
      "Collecting botocore<1.40.71,>=1.40.46 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached botocore-1.40.70-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.7.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.22.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from botocore<1.40.71,>=1.40.46->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/mkothari/miniforge3/lib/python3.12/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.15.0)\n",
      "Using cached botocore-1.40.70-py3-none-any.whl (14.1 MB)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.40.71\n",
      "    Uninstalling botocore-1.40.71:\n",
      "      Successfully uninstalled botocore-1.40.71\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.40.71 requires botocore<1.41.0,>=1.40.71, but you have botocore 1.40.70 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.40.70\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "!pip install cryoet-data-portal\n",
    "!pip install -e \".[plots,zarr-python-v3]\"\n",
    "!pip install s3fs  # For accessing S3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zarr'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzarr\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01ms3fs\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcryoet_data_portal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client, Dataset, Run, Tomogram\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'zarr'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import time\n",
    "import zarr\n",
    "import s3fs\n",
    "from cryoet_data_portal import Client, Dataset, Run, Tomogram\n",
    "from zarr_benchmarks.read_write_zarr import read_write_zarr\n",
    "from zarr_benchmarks import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to CryoET Data Portal\n",
    "\n",
    "Let's connect to the portal and explore dataset 10445."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = Client()\n",
    "\n",
    "# Get the dataset\n",
    "dataset = Dataset.get_by_id(client, 10445)\n",
    "\n",
    "print(f\"Dataset: {dataset.title}\")\n",
    "print(f\"Dataset ID: {dataset.id}\")\n",
    "print(f\"Description: {dataset.description[:200]}...\") if len(dataset.description) > 200 else print(f\"Description: {dataset.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Available Runs and Tomograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all runs for this dataset\n",
    "runs = list(dataset.runs)\n",
    "print(f\"Total number of runs: {len(runs)}\")\n",
    "\n",
    "# Get information about the first run\n",
    "first_run = runs[0]\n",
    "print(f\"\\nFirst run name: {first_run.name}\")\n",
    "print(f\"Run ID: {first_run.id}\")\n",
    "\n",
    "# Get tomograms from this run\n",
    "tomograms = list(first_run.tomograms)\n",
    "print(f\"\\nNumber of tomograms in first run: {len(tomograms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details about the first tomogram\n",
    "if tomograms:\n",
    "    first_tomogram = tomograms[0]\n",
    "    print(f\"Tomogram name: {first_tomogram.name}\")\n",
    "    print(f\"Tomogram size (x,y,z): {first_tomogram.size_x} x {first_tomogram.size_y} x {first_tomogram.size_z}\")\n",
    "    print(f\"Voxel spacing: {first_tomogram.voxel_spacing} Å\")\n",
    "    print(f\"S3 path: {first_tomogram.s3_omezarr_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Access Zarr Data from S3\n",
    "\n",
    "Now let's access the actual Zarr data from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 filesystem (anonymous access)\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "# Get the zarr path (removing the 's3://' prefix)\n",
    "if tomograms:\n",
    "    zarr_path = first_tomogram.s3_omezarr_dir.replace('s3://', '')\n",
    "    print(f\"Accessing zarr data at: {zarr_path}\")\n",
    "    \n",
    "    # Open the zarr array\n",
    "    store = s3fs.S3Map(root=zarr_path, s3=s3, check=False)\n",
    "    zarr_array = zarr.open(store, mode='r')\n",
    "    \n",
    "    print(f\"\\nZarr array shape: {zarr_array.shape}\")\n",
    "    print(f\"Zarr array dtype: {zarr_array.dtype}\")\n",
    "    print(f\"Zarr array chunks: {zarr_array.chunks}\")\n",
    "    print(f\"Zarr array compressor: {zarr_array.compressor}\")\n",
    "    print(f\"Zarr array size: {zarr_array.nbytes / (1024**3):.2f} GB (uncompressed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Benchmark Reading from S3\n",
    "\n",
    "Let's benchmark reading different portions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark 1: Read a single slice\n",
    "print(\"Benchmark 1: Reading a single XY slice\")\n",
    "start_time = time.time()\n",
    "single_slice = zarr_array[zarr_array.shape[0]//2, :, :]\n",
    "slice_time = time.time() - start_time\n",
    "print(f\"  Time: {slice_time:.3f}s\")\n",
    "print(f\"  Shape: {single_slice.shape}\")\n",
    "print(f\"  Size: {single_slice.nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "# Benchmark 2: Read a small 3D chunk\n",
    "print(\"\\nBenchmark 2: Reading a 128x128x128 chunk\")\n",
    "start_time = time.time()\n",
    "chunk_size = 128\n",
    "small_chunk = zarr_array[:chunk_size, :chunk_size, :chunk_size]\n",
    "chunk_time = time.time() - start_time\n",
    "print(f\"  Time: {chunk_time:.3f}s\")\n",
    "print(f\"  Shape: {small_chunk.shape}\")\n",
    "print(f\"  Size: {small_chunk.nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "# Benchmark 3: Read a larger chunk\n",
    "print(\"\\nBenchmark 3: Reading a 256x256x256 chunk\")\n",
    "start_time = time.time()\n",
    "chunk_size = 256\n",
    "if all(dim >= chunk_size for dim in zarr_array.shape):\n",
    "    medium_chunk = zarr_array[:chunk_size, :chunk_size, :chunk_size]\n",
    "    medium_chunk_time = time.time() - start_time\n",
    "    print(f\"  Time: {medium_chunk_time:.3f}s\")\n",
    "    print(f\"  Shape: {medium_chunk.shape}\")\n",
    "    print(f\"  Size: {medium_chunk.nbytes / (1024**2):.2f} MB\")\n",
    "else:\n",
    "    print(\"  Skipped: tomogram is smaller than 256x256x256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize a Slice\n",
    "\n",
    "Let's visualize a slice from the tomogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the middle slice\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# XY slice (middle Z)\n",
    "mid_z = zarr_array.shape[0] // 2\n",
    "xy_slice = zarr_array[mid_z, :, :]\n",
    "axes[0].imshow(xy_slice, cmap='gray')\n",
    "axes[0].set_title(f'XY Slice (Z={mid_z})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# XZ slice (middle Y)\n",
    "mid_y = zarr_array.shape[1] // 2\n",
    "xz_slice = zarr_array[:, mid_y, :]\n",
    "axes[1].imshow(xz_slice, cmap='gray')\n",
    "axes[1].set_title(f'XZ Slice (Y={mid_y})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# YZ slice (middle X)\n",
    "mid_x = zarr_array.shape[2] // 2\n",
    "yz_slice = zarr_array[:, :, mid_x]\n",
    "axes[2].imshow(yz_slice, cmap='gray')\n",
    "axes[2].set_title(f'YZ Slice (X={mid_x})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download and Re-compress with Different Codecs\n",
    "\n",
    "Now let's download a chunk of data and test different compression methods using zarr-benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a manageable chunk for benchmarking\n",
    "chunk_size = 256\n",
    "if all(dim >= chunk_size for dim in zarr_array.shape):\n",
    "    test_data = zarr_array[:chunk_size, :chunk_size, :chunk_size]\n",
    "else:\n",
    "    # Use the full array if it's smaller\n",
    "    test_data = zarr_array[:]\n",
    "\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Test data size: {test_data.nbytes / (1024**2):.2f} MB\")\n",
    "print(f\"Test data dtype: {test_data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for re-compression benchmarks\n",
    "output_dir = pathlib.Path(\"data/output/cryoet_benchmarks\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chunk_size_recompress = 64\n",
    "chunks = (chunk_size_recompress, chunk_size_recompress, chunk_size_recompress)\n",
    "zarr_spec = 3\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(f\"Original compression: {zarr_array.compressor}\")\n",
    "print(f\"Testing re-compression with chunk size: {chunk_size_recompress}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Test Blosc Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blosc compression\n",
    "store_path = output_dir / \"cryoet_blosc.zarr\"\n",
    "blosc_compressor = read_write_zarr.get_blosc_compressor(\n",
    "    cname=\"zstd\",\n",
    "    clevel=5,\n",
    "    shuffle=\"shuffle\",\n",
    "    zarr_spec=zarr_spec\n",
    ")\n",
    "\n",
    "utils.remove_output_dir(store_path)\n",
    "start_time = time.time()\n",
    "read_write_zarr.write_zarr_array(\n",
    "    test_data,\n",
    "    store_path,\n",
    "    overwrite=False,\n",
    "    chunks=chunks,\n",
    "    compressor=blosc_compressor,\n",
    "    zarr_spec=zarr_spec\n",
    ")\n",
    "write_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "read_back = read_write_zarr.read_zarr_array(store_path)\n",
    "read_time = time.time() - start_time\n",
    "\n",
    "compression_ratio = read_write_zarr.get_compression_ratio(store_path)\n",
    "storage_size = utils.get_directory_size(store_path) / (1024**2)\n",
    "\n",
    "results['blosc_zstd'] = {\n",
    "    'write_time': write_time,\n",
    "    'read_time': read_time,\n",
    "    'compression_ratio': compression_ratio,\n",
    "    'storage_size_mb': storage_size\n",
    "}\n",
    "\n",
    "print(f\"Blosc-Zstd Results:\")\n",
    "print(f\"  Write time: {write_time:.3f}s\")\n",
    "print(f\"  Read time: {read_time:.3f}s\")\n",
    "print(f\"  Compression ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"  Storage size: {storage_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Test GZip Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GZip compression\n",
    "store_path = output_dir / \"cryoet_gzip.zarr\"\n",
    "gzip_compressor = read_write_zarr.get_gzip_compressor(\n",
    "    level=6,\n",
    "    zarr_spec=zarr_spec\n",
    ")\n",
    "\n",
    "utils.remove_output_dir(store_path)\n",
    "start_time = time.time()\n",
    "read_write_zarr.write_zarr_array(\n",
    "    test_data,\n",
    "    store_path,\n",
    "    overwrite=False,\n",
    "    chunks=chunks,\n",
    "    compressor=gzip_compressor,\n",
    "    zarr_spec=zarr_spec\n",
    ")\n",
    "write_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "read_back = read_write_zarr.read_zarr_array(store_path)\n",
    "read_time = time.time() - start_time\n",
    "\n",
    "compression_ratio = read_write_zarr.get_compression_ratio(store_path)\n",
    "storage_size = utils.get_directory_size(store_path) / (1024**2)\n",
    "\n",
    "results['gzip'] = {\n",
    "    'write_time': write_time,\n",
    "    'read_time': read_time,\n",
    "    'compression_ratio': compression_ratio,\n",
    "    'storage_size_mb': storage_size\n",
    "}\n",
    "\n",
    "print(f\"GZip Results:\")\n",
    "print(f\"  Write time: {write_time:.3f}s\")\n",
    "print(f\"  Read time: {read_time:.3f}s\")\n",
    "print(f\"  Compression ratio: {compression_ratio:.2f}x\")\n",
    "print(f\"  Storage size: {storage_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Test Different Blosc Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different Blosc algorithms: lz4 (fast) vs zstd (balanced)\n",
    "for cname in ['lz4', 'zlib']:\n",
    "    store_path = output_dir / f\"cryoet_blosc_{cname}.zarr\"\n",
    "    blosc_compressor = read_write_zarr.get_blosc_compressor(\n",
    "        cname=cname,\n",
    "        clevel=5,\n",
    "        shuffle=\"shuffle\",\n",
    "        zarr_spec=zarr_spec\n",
    "    )\n",
    "    \n",
    "    utils.remove_output_dir(store_path)\n",
    "    start_time = time.time()\n",
    "    read_write_zarr.write_zarr_array(\n",
    "        test_data,\n",
    "        store_path,\n",
    "        overwrite=False,\n",
    "        chunks=chunks,\n",
    "        compressor=blosc_compressor,\n",
    "        zarr_spec=zarr_spec\n",
    "    )\n",
    "    write_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    read_back = read_write_zarr.read_zarr_array(store_path)\n",
    "    read_time = time.time() - start_time\n",
    "    \n",
    "    compression_ratio = read_write_zarr.get_compression_ratio(store_path)\n",
    "    storage_size = utils.get_directory_size(store_path) / (1024**2)\n",
    "    \n",
    "    results[f'blosc_{cname}'] = {\n",
    "        'write_time': write_time,\n",
    "        'read_time': read_time,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'storage_size_mb': storage_size\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nBlosc-{cname} Results:\")\n",
    "    print(f\"  Write time: {write_time:.3f}s\")\n",
    "    print(f\"  Read time: {read_time:.3f}s\")\n",
    "    print(f\"  Compression ratio: {compression_ratio:.2f}x\")\n",
    "    print(f\"  Storage size: {storage_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "methods = list(results.keys())\n",
    "write_times = [results[m]['write_time'] for m in methods]\n",
    "read_times = [results[m]['read_time'] for m in methods]\n",
    "compression_ratios = [results[m]['compression_ratio'] for m in methods]\n",
    "storage_sizes = [results[m]['storage_size_mb'] for m in methods]\n",
    "\n",
    "# Plot 1: Write times\n",
    "axes[0, 0].bar(methods, write_times, color='steelblue')\n",
    "axes[0, 0].set_ylabel('Time (seconds)')\n",
    "axes[0, 0].set_title('Write Performance for CryoET Data')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Read times\n",
    "axes[0, 1].bar(methods, read_times, color='coral')\n",
    "axes[0, 1].set_ylabel('Time (seconds)')\n",
    "axes[0, 1].set_title('Read Performance for CryoET Data')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Compression ratios\n",
    "axes[1, 0].bar(methods, compression_ratios, color='green')\n",
    "axes[1, 0].set_ylabel('Compression Ratio')\n",
    "axes[1, 0].set_title('Compression Ratio (Higher is Better)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 4: Storage sizes\n",
    "axes[1, 1].bar(methods, storage_sizes, color='purple')\n",
    "axes[1, 1].set_ylabel('Size (MB)')\n",
    "axes[1, 1].set_title('Storage Size (Lower is Better)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "summary_df = pd.DataFrame(results).T\n",
    "summary_df = summary_df.round(3)\n",
    "summary_df.columns = ['Write Time (s)', 'Read Time (s)', 'Compression Ratio', 'Storage Size (MB)']\n",
    "\n",
    "print(\"\\n=== CryoET Data Compression Benchmark Summary ===\")\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\nBest Methods:\")\n",
    "print(f\"  Fastest write: {summary_df['Write Time (s)'].idxmin()}\")\n",
    "print(f\"  Fastest read: {summary_df['Read Time (s)'].idxmin()}\")\n",
    "print(f\"  Best compression: {summary_df['Compression Ratio'].idxmax()}\")\n",
    "print(f\"  Smallest storage: {summary_df['Storage Size (MB)'].idxmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Explore More Tomograms\n",
    "\n",
    "You can iterate through other tomograms in the dataset to test different data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tomogram details in the first run\n",
    "print(\"Available tomograms in the first run:\")\n",
    "print(\"=\"*80)\n",
    "for i, tomo in enumerate(tomograms[:5]):  # Show first 5\n",
    "    print(f\"\\n{i+1}. {tomo.name}\")\n",
    "    print(f\"   Size: {tomo.size_x} x {tomo.size_y} x {tomo.size_z}\")\n",
    "    print(f\"   Voxel spacing: {tomo.voxel_spacing} Å\")\n",
    "    print(f\"   S3 path: {tomo.s3_omezarr_dir}\")\n",
    "    \n",
    "if len(tomograms) > 5:\n",
    "    print(f\"\\n... and {len(tomograms) - 5} more tomograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps and Recommendations\n",
    "\n",
    "### Key Findings for CryoET Data\n",
    "\n",
    "Based on the benchmarks above, you can now make informed decisions about:\n",
    "\n",
    "1. **Compression Method**: Which codec provides the best balance of speed and compression for your use case\n",
    "2. **Chunk Size**: How chunk size affects access patterns (test with different sizes)\n",
    "3. **Storage vs Speed**: Trade-offs between storage space and read/write performance\n",
    "\n",
    "### Recommendations for CryoET Data\n",
    "\n",
    "- **For interactive analysis**: Use Blosc with LZ4 or Zstd (fast compression/decompression)\n",
    "- **For archival storage**: Use GZip or Blosc with Zlib (better compression ratios)\n",
    "- **For streaming access**: Consider chunk sizes that match your typical access patterns\n",
    "\n",
    "### Further Exploration\n",
    "\n",
    "1. Test with different tomograms (sparse vs dense data)\n",
    "2. Benchmark different chunk sizes (32, 64, 128, 256)\n",
    "3. Try different compression levels\n",
    "4. Test partial reads vs full reads\n",
    "5. Compare with other runs and datasets\n",
    "\n",
    "### Resources\n",
    "\n",
    "- CryoET Portal: https://cryoetdataportal.czscience.com/\n",
    "- CryoET API Docs: https://chanzuckerberg.github.io/cryoet-data-portal/\n",
    "- Zarr Benchmarks Docs: https://heftieproject.github.io/zarr-benchmarks/\n",
    "- Dataset 10445: https://cryoetdataportal.czscience.com/datasets/10445"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
