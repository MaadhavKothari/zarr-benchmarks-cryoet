{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# CryoET Quality Control & Benchmarking Tool\n",
    "\n",
    "## Overview\n",
    "\n",
    "Inspired by [PixelPatrol](https://helmholtz-imaging.de/news/pixelpatrol-scientific-image-quality-control/), this tool provides:\n",
    "\n",
    "### Quality Control Features (PixelPatrol-style):\n",
    "- ðŸ“Š **Dataset profiling**: Metadata and pixel distribution analysis\n",
    "- ðŸ” **Outlier detection**: Identify anomalies and inconsistencies\n",
    "- ðŸ“ˆ **Statistical validation**: Comprehensive data integrity checks\n",
    "- ðŸŽ¯ **Visual inspection**: Interactive dashboards and plots\n",
    "\n",
    "### Benchmarking Integration:\n",
    "- ðŸ—œï¸ **Compression testing**: Multiple codec configurations\n",
    "- âœ… **Data integrity**: Verify lossless compression\n",
    "- âš¡ **Performance metrics**: Speed and throughput analysis\n",
    "- ðŸ’¾ **Storage optimization**: Best compression recommendations\n",
    "\n",
    "### Combined Analysis:\n",
    "- ðŸ”¬ **Pre-compression QC**: Validate data quality before compression\n",
    "- ðŸ§ª **Post-compression QC**: Ensure no data corruption\n",
    "- ðŸ“‹ **Automated reports**: Comprehensive QC + benchmark dashboards\n",
    "- âœ¨ **Smart recommendations**: Data-driven optimization suggestions\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow\n",
    "\n",
    "```\n",
    "1. Load Data â†’ 2. Pre-QC â†’ 3. Benchmark â†’ 4. Post-QC â†’ 5. Report\n",
    "```\n",
    "\n",
    "This ensures:\n",
    "- Data is valid before compression\n",
    "- Compression is lossless\n",
    "- Performance is optimal\n",
    "- Results are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import pathlib\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import seaborn as sns\n",
    "import zarr\n",
    "from cryoet_data_portal import Client, Dataset\n",
    "from scipy import stats\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "from zarr_benchmarks import utils\n",
    "from zarr_benchmarks.read_write_zarr import read_write_zarr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "print(\"âœ“ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "DOWNLOAD_SIZE = 256\n",
    "DATASET_ID = 10445\n",
    "\n",
    "# QC thresholds\n",
    "QC_THRESHOLDS = {\n",
    "    \"outlier_std\": 3.0,  # Standard deviations for outlier detection\n",
    "    \"min_snr\": 1.0,  # Minimum signal-to-noise ratio\n",
    "    \"max_saturation\": 0.01,  # Maximum fraction of saturated pixels\n",
    "    \"min_dynamic_range\": 100,  # Minimum intensity range\n",
    "}\n",
    "\n",
    "# Benchmark configuration\n",
    "BENCHMARK_CODECS = [\n",
    "    (\"blosc_zstd\", \"shuffle\", 3),\n",
    "    (\"blosc_zstd\", \"shuffle\", 5),\n",
    "    (\"blosc_lz4\", \"shuffle\", 5),\n",
    "    (\"zstd\", None, 5),\n",
    "]\n",
    "\n",
    "CHUNK_SIZE = 128\n",
    "ZARR_SPEC = 2\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = pathlib.Path(\"data/output/qc_benchmark\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Download size: {DOWNLOAD_SIZE}Â³\")\n",
    "print(f\"  Dataset ID: {DATASET_ID}\")\n",
    "print(f\"  Benchmark codecs: {len(BENCHMARK_CODECS)}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qc-class-header",
   "metadata": {},
   "source": [
    "## QC Analysis Class\n",
    "\n",
    "Implements PixelPatrol-inspired quality control checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qc-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryoETQualityControl:\n",
    "    \"\"\"Quality Control for CryoET tomogram data\"\"\"\n",
    "\n",
    "    def __init__(self, data, name=\"tomogram\", thresholds=None):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.thresholds = thresholds or QC_THRESHOLDS\n",
    "        self.report = {}\n",
    "\n",
    "    def run_all_checks(self):\n",
    "        \"\"\"Run comprehensive QC analysis\"\"\"\n",
    "        print(f\"Running QC checks on {self.name}...\")\n",
    "\n",
    "        self.check_basic_stats()\n",
    "        self.check_distribution()\n",
    "        self.check_outliers()\n",
    "        self.check_snr()\n",
    "        self.check_dynamic_range()\n",
    "        self.check_saturation()\n",
    "        self.check_spatial_consistency()\n",
    "\n",
    "        self.report[\"timestamp\"] = datetime.now().isoformat()\n",
    "        self.report[\"status\"] = self.determine_status()\n",
    "\n",
    "        return self.report\n",
    "\n",
    "    def check_basic_stats(self):\n",
    "        \"\"\"Basic statistical properties\"\"\"\n",
    "        self.report[\"shape\"] = self.data.shape\n",
    "        self.report[\"dtype\"] = str(self.data.dtype)\n",
    "        self.report[\"size_mb\"] = self.data.nbytes / (1024**2)\n",
    "        self.report[\"min\"] = float(np.min(self.data))\n",
    "        self.report[\"max\"] = float(np.max(self.data))\n",
    "        self.report[\"mean\"] = float(np.mean(self.data))\n",
    "        self.report[\"std\"] = float(np.std(self.data))\n",
    "        self.report[\"median\"] = float(np.median(self.data))\n",
    "\n",
    "    def check_distribution(self):\n",
    "        \"\"\"Analyze pixel value distribution\"\"\"\n",
    "        # Histogram statistics\n",
    "        hist, bin_edges = np.histogram(self.data, bins=100)\n",
    "        self.report[\"histogram\"] = {\n",
    "            \"counts\": hist.tolist(),\n",
    "            \"bin_edges\": bin_edges.tolist(),\n",
    "        }\n",
    "\n",
    "        # Distribution tests\n",
    "        self.report[\"skewness\"] = float(stats.skew(self.data.flatten()))\n",
    "        self.report[\"kurtosis\"] = float(stats.kurtosis(self.data.flatten()))\n",
    "\n",
    "    def check_outliers(self):\n",
    "        \"\"\"Detect outlier pixels\"\"\"\n",
    "        mean = self.report[\"mean\"]\n",
    "        std = self.report[\"std\"]\n",
    "        threshold = self.thresholds[\"outlier_std\"]\n",
    "\n",
    "        outliers = np.abs(self.data - mean) > (threshold * std)\n",
    "        n_outliers = np.sum(outliers)\n",
    "\n",
    "        self.report[\"outliers\"] = {\n",
    "            \"count\": int(n_outliers),\n",
    "            \"fraction\": float(n_outliers / self.data.size),\n",
    "            \"threshold_std\": threshold,\n",
    "        }\n",
    "\n",
    "    def check_snr(self):\n",
    "        \"\"\"Estimate signal-to-noise ratio\"\"\"\n",
    "        # Simple SNR estimate: mean / std\n",
    "        snr = abs(self.report[\"mean\"]) / (self.report[\"std\"] + 1e-10)\n",
    "\n",
    "        self.report[\"snr\"] = {\n",
    "            \"value\": float(snr),\n",
    "            \"pass\": snr >= self.thresholds[\"min_snr\"],\n",
    "        }\n",
    "\n",
    "    def check_dynamic_range(self):\n",
    "        \"\"\"Check intensity dynamic range\"\"\"\n",
    "        data_range = self.report[\"max\"] - self.report[\"min\"]\n",
    "\n",
    "        self.report[\"dynamic_range\"] = {\n",
    "            \"value\": float(data_range),\n",
    "            \"pass\": data_range >= self.thresholds[\"min_dynamic_range\"],\n",
    "        }\n",
    "\n",
    "    def check_saturation(self):\n",
    "        \"\"\"Check for saturated pixels\"\"\"\n",
    "        # Assume saturation near min/max for float data\n",
    "        data_min, data_max = self.report[\"min\"], self.report[\"max\"]\n",
    "        margin = (data_max - data_min) * 0.01\n",
    "\n",
    "        saturated_low = np.sum(self.data <= (data_min + margin))\n",
    "        saturated_high = np.sum(self.data >= (data_max - margin))\n",
    "        total_saturated = saturated_low + saturated_high\n",
    "\n",
    "        saturation_fraction = total_saturated / self.data.size\n",
    "\n",
    "        self.report[\"saturation\"] = {\n",
    "            \"low_count\": int(saturated_low),\n",
    "            \"high_count\": int(saturated_high),\n",
    "            \"fraction\": float(saturation_fraction),\n",
    "            \"pass\": saturation_fraction <= self.thresholds[\"max_saturation\"],\n",
    "        }\n",
    "\n",
    "    def check_spatial_consistency(self):\n",
    "        \"\"\"Check for spatial anomalies\"\"\"\n",
    "        # Analyze variance across z-slices\n",
    "        slice_means = np.mean(self.data, axis=(1, 2))\n",
    "        slice_stds = np.std(self.data, axis=(1, 2))\n",
    "\n",
    "        self.report[\"spatial\"] = {\n",
    "            \"slice_mean_std\": float(np.std(slice_means)),\n",
    "            \"slice_std_std\": float(np.std(slice_stds)),\n",
    "            \"mean_consistency\": float(\n",
    "                np.std(slice_means) / (abs(np.mean(slice_means)) + 1e-10)\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def determine_status(self):\n",
    "        \"\"\"Overall QC status\"\"\"\n",
    "        checks = [\n",
    "            self.report[\"snr\"][\"pass\"],\n",
    "            self.report[\"dynamic_range\"][\"pass\"],\n",
    "            self.report[\"saturation\"][\"pass\"],\n",
    "            self.report[\"outliers\"][\"fraction\"] < 0.05,  # <5% outliers\n",
    "        ]\n",
    "\n",
    "        if all(checks):\n",
    "            return \"PASS\"\n",
    "        elif sum(checks) >= len(checks) * 0.75:\n",
    "            return \"WARNING\"\n",
    "        else:\n",
    "            return \"FAIL\"\n",
    "\n",
    "    def visualize(self, save_path=None):\n",
    "        \"\"\"Create QC visualization dashboard\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "        # Row 1: Orthogonal slices\n",
    "        mid_z, mid_y, mid_x = [s // 2 for s in self.data.shape]\n",
    "\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        im1 = ax1.imshow(self.data[mid_z], cmap=\"gray\")\n",
    "        ax1.set_title(f\"XY Slice (Z={mid_z})\")\n",
    "        ax1.axis(\"off\")\n",
    "        plt.colorbar(im1, ax=ax1, fraction=0.046)\n",
    "\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        im2 = ax2.imshow(self.data[:, mid_y, :], cmap=\"gray\")\n",
    "        ax2.set_title(f\"XZ Slice (Y={mid_y})\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.colorbar(im2, ax=ax2, fraction=0.046)\n",
    "\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        im3 = ax3.imshow(self.data[:, :, mid_x], cmap=\"gray\")\n",
    "        ax3.set_title(f\"YZ Slice (X={mid_x})\")\n",
    "        ax3.axis(\"off\")\n",
    "        plt.colorbar(im3, ax=ax3, fraction=0.046)\n",
    "\n",
    "        # Row 2: Distribution analysis\n",
    "        ax4 = fig.add_subplot(gs[1, 0])\n",
    "        ax4.hist(\n",
    "            self.data.flatten(),\n",
    "            bins=100,\n",
    "            alpha=0.7,\n",
    "            color=\"steelblue\",\n",
    "            edgecolor=\"black\",\n",
    "        )\n",
    "        ax4.axvline(\n",
    "            self.report[\"mean\"],\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=f\"Mean: {self.report['mean']:.2f}\",\n",
    "        )\n",
    "        ax4.axvline(\n",
    "            self.report[\"median\"],\n",
    "            color=\"green\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=2,\n",
    "            label=f\"Median: {self.report['median']:.2f}\",\n",
    "        )\n",
    "        ax4.set_xlabel(\"Intensity\")\n",
    "        ax4.set_ylabel(\"Frequency\")\n",
    "        ax4.set_title(\"Intensity Distribution\")\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "\n",
    "        ax5 = fig.add_subplot(gs[1, 1])\n",
    "        slice_means = np.mean(self.data, axis=(1, 2))\n",
    "        ax5.plot(slice_means, linewidth=2, color=\"navy\")\n",
    "        ax5.set_xlabel(\"Z Slice\")\n",
    "        ax5.set_ylabel(\"Mean Intensity\")\n",
    "        ax5.set_title(\"Spatial Consistency (Z)\")\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "\n",
    "        ax6 = fig.add_subplot(gs[1, 2])\n",
    "        slice_stds = np.std(self.data, axis=(1, 2))\n",
    "        ax6.plot(slice_stds, linewidth=2, color=\"darkred\")\n",
    "        ax6.set_xlabel(\"Z Slice\")\n",
    "        ax6.set_ylabel(\"Std Dev\")\n",
    "        ax6.set_title(\"Noise Profile (Z)\")\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "\n",
    "        # Row 3: QC metrics\n",
    "        ax7 = fig.add_subplot(gs[2, :])\n",
    "        ax7.axis(\"off\")\n",
    "\n",
    "        qc_text = f\"\"\"QC REPORT: {self.name}\n",
    "        \n",
    "Status: {self.report[\"status\"]}\n",
    "Shape: {self.report[\"shape\"]}\n",
    "Size: {self.report[\"size_mb\"]:.2f} MB\n",
    "\n",
    "Intensity Statistics:\n",
    "  Range: [{self.report[\"min\"]:.3f}, {self.report[\"max\"]:.3f}]\n",
    "  Mean: {self.report[\"mean\"]:.3f} Â± {self.report[\"std\"]:.3f}\n",
    "  Median: {self.report[\"median\"]:.3f}\n",
    "  Skewness: {self.report[\"skewness\"]:.3f}\n",
    "  Kurtosis: {self.report[\"kurtosis\"]:.3f}\n",
    "\n",
    "Quality Metrics:\n",
    "  SNR: {self.report[\"snr\"][\"value\"]:.2f} {\"âœ“\" if self.report[\"snr\"][\"pass\"] else \"âœ—\"}\n",
    "  Dynamic Range: {self.report[\"dynamic_range\"][\"value\"]:.2f} {\"âœ“\" if self.report[\"dynamic_range\"][\"pass\"] else \"âœ—\"}\n",
    "  Saturation: {self.report[\"saturation\"][\"fraction\"] * 100:.2f}% {\"âœ“\" if self.report[\"saturation\"][\"pass\"] else \"âœ—\"}\n",
    "  Outliers: {self.report[\"outliers\"][\"fraction\"] * 100:.2f}% ({self.report[\"outliers\"][\"count\"]} pixels)\n",
    "\n",
    "Spatial Consistency:\n",
    "  Mean variation: {self.report[\"spatial\"][\"mean_consistency\"]:.4f}\n",
    "  Slice std deviation: {self.report[\"spatial\"][\"slice_std_std\"]:.3f}\n",
    "        \"\"\"\n",
    "\n",
    "        ax7.text(\n",
    "            0.05,\n",
    "            0.95,\n",
    "            qc_text,\n",
    "            transform=ax7.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment=\"top\",\n",
    "            family=\"monospace\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5),\n",
    "        )\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"Quality Control Dashboard: {self.name}\", fontsize=16, fontweight=\"bold\"\n",
    "        )\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"âœ“ QC class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 1. Download CryoET Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to CryoET Data Portal...\")\n",
    "client = Client()\n",
    "dataset = Dataset.get_by_id(client, DATASET_ID)\n",
    "\n",
    "print(f\"âœ“ Dataset: {dataset.title}\")\n",
    "\n",
    "# Find tomogram\n",
    "runs = list(dataset.runs)\n",
    "selected_tomo = None\n",
    "for run in runs:\n",
    "    for tomo in list(run.tomograms):\n",
    "        if (\n",
    "            tomo.size_x >= DOWNLOAD_SIZE\n",
    "            and tomo.size_y >= DOWNLOAD_SIZE\n",
    "            and tomo.size_z >= DOWNLOAD_SIZE\n",
    "        ):\n",
    "            selected_tomo = tomo\n",
    "            break\n",
    "    if selected_tomo:\n",
    "        break\n",
    "\n",
    "print(f\"âœ“ Selected: {selected_tomo.name}\")\n",
    "\n",
    "# Download data\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "zarr_path = selected_tomo.s3_omezarr_dir.replace(\"s3://\", \"\")\n",
    "store = s3fs.S3Map(root=zarr_path, s3=s3, check=False)\n",
    "zarr_group = zarr.open(store, mode=\"r\")\n",
    "zarr_array = zarr_group[\"0\"]\n",
    "\n",
    "# Download centered cube\n",
    "actual_size = min(DOWNLOAD_SIZE, min(zarr_array.shape))\n",
    "z_c = zarr_array.shape[0] // 2\n",
    "y_c = zarr_array.shape[1] // 2\n",
    "x_c = zarr_array.shape[2] // 2\n",
    "\n",
    "z_start = max(0, z_c - actual_size // 2)\n",
    "z_end = min(zarr_array.shape[0], z_start + actual_size)\n",
    "y_start = max(0, y_c - actual_size // 2)\n",
    "y_end = min(zarr_array.shape[1], y_start + actual_size)\n",
    "x_start = max(0, x_c - actual_size // 2)\n",
    "x_end = min(zarr_array.shape[2], x_start + actual_size)\n",
    "\n",
    "print(f\"\\nDownloading {actual_size}Â³ cube...\")\n",
    "reference_data = np.array(zarr_array[z_start:z_end, y_start:y_end, x_start:x_end])\n",
    "\n",
    "print(f\"âœ“ Downloaded: {reference_data.shape}\")\n",
    "print(f\"  Size: {reference_data.nbytes / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pre-qc-header",
   "metadata": {},
   "source": [
    "## 2. Pre-Compression Quality Control\n",
    "\n",
    "Validate data quality before compression testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pre-qc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PRE-COMPRESSION QUALITY CONTROL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run QC on original data\n",
    "qc_original = CryoETQualityControl(reference_data, name=\"Original Data\")\n",
    "pre_qc_report = qc_original.run_all_checks()\n",
    "\n",
    "print(f\"\\nâœ“ QC Status: {pre_qc_report['status']}\")\n",
    "\n",
    "# Visualize\n",
    "qc_original.visualize(save_path=OUTPUT_DIR / \"qc_original.png\")\n",
    "\n",
    "# Save report\n",
    "with open(OUTPUT_DIR / \"qc_pre_compression.json\", \"w\") as f:\n",
    "    json.dump(pre_qc_report, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ“ Pre-compression QC complete\")\n",
    "print(f\"  Report saved to: {OUTPUT_DIR / 'qc_pre_compression.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-header",
   "metadata": {},
   "source": [
    "## 3. Compression Benchmarking with QC\n",
    "\n",
    "Test compression while monitoring data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPRESSION BENCHMARKING WITH QC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "benchmark_results = []\n",
    "qc_results = {}\n",
    "\n",
    "for idx, (codec, shuffle, level) in enumerate(BENCHMARK_CODECS):\n",
    "    print(\n",
    "        f\"\\n[{idx + 1}/{len(BENCHMARK_CODECS)}] Testing: {codec} (shuffle={shuffle}, level={level})\"\n",
    "    )\n",
    "\n",
    "    # Create unique name\n",
    "    config_name = f\"{codec}_{shuffle}_{level}\" if shuffle else f\"{codec}_L{level}\"\n",
    "    store_path = OUTPUT_DIR / f\"{config_name}.zarr\"\n",
    "    utils.remove_output_dir(store_path)\n",
    "\n",
    "    # Get compressor\n",
    "    chunks = (CHUNK_SIZE, CHUNK_SIZE, CHUNK_SIZE)\n",
    "\n",
    "    if \"blosc\" in codec:\n",
    "        cname = codec.split(\"_\")[1]\n",
    "        compressor = read_write_zarr.get_blosc_compressor(cname, level, shuffle)\n",
    "    elif codec == \"zstd\":\n",
    "        compressor = read_write_zarr.get_zstd_compressor(level)\n",
    "    else:\n",
    "        compressor = read_write_zarr.get_gzip_compressor(level)\n",
    "\n",
    "    # Benchmark write\n",
    "    t0 = time.time()\n",
    "    read_write_zarr.write_zarr_array(\n",
    "        reference_data,\n",
    "        store_path,\n",
    "        overwrite=False,\n",
    "        chunks=chunks,\n",
    "        compressor=compressor,\n",
    "        zarr_spec=ZARR_SPEC,\n",
    "    )\n",
    "    write_time = time.time() - t0\n",
    "\n",
    "    # Benchmark read\n",
    "    t0 = time.time()\n",
    "    read_back = read_write_zarr.read_zarr_array(store_path)\n",
    "    read_time = time.time() - t0\n",
    "\n",
    "    # Get metrics\n",
    "    ratio = read_write_zarr.get_compression_ratio(store_path)\n",
    "    size_mb = utils.get_directory_size(store_path) / (1024**2)\n",
    "\n",
    "    # Quality metrics\n",
    "    ssim_val = ssim(\n",
    "        (reference_data[reference_data.shape[0] // 2] - reference_data.min())\n",
    "        / (reference_data.max() - reference_data.min() + 1e-10),\n",
    "        (read_back[read_back.shape[0] // 2] - read_back.min())\n",
    "        / (read_back.max() - read_back.min() + 1e-10),\n",
    "        data_range=1.0,\n",
    "    )\n",
    "\n",
    "    data_range = reference_data.max() - reference_data.min()\n",
    "    psnr_val = psnr(reference_data, read_back, data_range=data_range)\n",
    "    mse_val = mse(reference_data, read_back)\n",
    "\n",
    "    # Post-compression QC\n",
    "    print(\"  Running post-compression QC...\")\n",
    "    qc_compressed = CryoETQualityControl(read_back, name=config_name)\n",
    "    qc_report = qc_compressed.run_all_checks()\n",
    "    qc_results[config_name] = qc_report\n",
    "\n",
    "    # Store results\n",
    "    benchmark_results.append(\n",
    "        {\n",
    "            \"config\": config_name,\n",
    "            \"codec\": codec,\n",
    "            \"shuffle\": shuffle or \"N/A\",\n",
    "            \"level\": level,\n",
    "            \"write_time\": write_time,\n",
    "            \"read_time\": read_time,\n",
    "            \"ratio\": ratio,\n",
    "            \"size_mb\": size_mb,\n",
    "            \"ssim\": ssim_val,\n",
    "            \"psnr\": psnr_val,\n",
    "            \"mse\": mse_val,\n",
    "            \"qc_status\": qc_report[\"status\"],\n",
    "            \"qc_snr\": qc_report[\"snr\"][\"value\"],\n",
    "            \"data_identical\": np.array_equal(reference_data, read_back),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"  Write: {write_time:.3f}s, Read: {read_time:.3f}s\")\n",
    "    print(f\"  Ratio: {ratio:.3f}Ã—, Size: {size_mb:.2f} MB\")\n",
    "    print(f\"  QC Status: {qc_report['status']}, SSIM: {ssim_val:.6f}\")\n",
    "    print(f\"  Data identical: {np.array_equal(reference_data, read_back)}\")\n",
    "\n",
    "print(\"\\nâœ“ Benchmark complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 4. QC Comparison: Before vs After Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "df_bench = pd.DataFrame(benchmark_results)\n",
    "\n",
    "# Save results\n",
    "df_bench.to_csv(OUTPUT_DIR / \"benchmark_with_qc.csv\", index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QC COMPARISON: ORIGINAL vs COMPRESSED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nOriginal Data QC:\")\n",
    "print(f\"  Status: {pre_qc_report['status']}\")\n",
    "print(f\"  SNR: {pre_qc_report['snr']['value']:.2f}\")\n",
    "print(f\"  Dynamic Range: {pre_qc_report['dynamic_range']['value']:.2f}\")\n",
    "print(f\"  Outliers: {pre_qc_report['outliers']['fraction'] * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nCompressed Data QC:\")\n",
    "for config in df_bench[\"config\"]:\n",
    "    qc_rep = qc_results[config]\n",
    "    print(\n",
    "        f\"  {config:30s}: Status={qc_rep['status']}, SNR={qc_rep['snr']['value']:.2f}\"\n",
    "    )\n",
    "\n",
    "# Check if all compressions preserved data\n",
    "all_identical = df_bench[\"data_identical\"].all()\n",
    "print(f\"\\nâœ“ All compressions are lossless: {all_identical}\")\n",
    "print(f\"âœ“ All QC checks passed: {(df_bench['qc_status'] == 'PASS').all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 5. Integrated QC + Benchmark Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Compression Ratio vs Time\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "colors = [\"green\" if s == \"PASS\" else \"orange\" for s in df_bench[\"qc_status\"]]\n",
    "ax1.scatter(\n",
    "    df_bench[\"write_time\"],\n",
    "    df_bench[\"ratio\"],\n",
    "    c=colors,\n",
    "    s=200,\n",
    "    alpha=0.6,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "for idx, row in df_bench.iterrows():\n",
    "    ax1.annotate(\n",
    "        row[\"config\"],\n",
    "        (row[\"write_time\"], row[\"ratio\"]),\n",
    "        fontsize=8,\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "ax1.set_xlabel(\"Write Time (s)\")\n",
    "ax1.set_ylabel(\"Compression Ratio\")\n",
    "ax1.set_title(\"Compression vs Speed (color=QC status)\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: SSIM Quality\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax2.bar(range(len(df_bench)), df_bench[\"ssim\"], color=\"steelblue\", alpha=0.7)\n",
    "ax2.set_xticks(range(len(df_bench)))\n",
    "ax2.set_xticklabels(df_bench[\"config\"], rotation=45, ha=\"right\", fontsize=8)\n",
    "ax2.set_ylabel(\"SSIM\")\n",
    "ax2.set_title(\"Image Quality (SSIM)\")\n",
    "ax2.axhline(y=1.0, color=\"red\", linestyle=\"--\", label=\"Perfect\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Storage Savings\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "savings = (1 - df_bench[\"size_mb\"] / pre_qc_report[\"size_mb\"]) * 100\n",
    "ax3.bar(range(len(df_bench)), savings, color=\"green\", alpha=0.7)\n",
    "ax3.set_xticks(range(len(df_bench)))\n",
    "ax3.set_xticklabels(df_bench[\"config\"], rotation=45, ha=\"right\", fontsize=8)\n",
    "ax3.set_ylabel(\"Storage Savings (%)\")\n",
    "ax3.set_title(\"Storage Reduction\")\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: SNR Comparison\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "snr_values = [pre_qc_report[\"snr\"][\"value\"]] + df_bench[\"qc_snr\"].tolist()\n",
    "labels = [\"Original\"] + df_bench[\"config\"].tolist()\n",
    "ax4.bar(range(len(snr_values)), snr_values, alpha=0.7)\n",
    "ax4.set_xticks(range(len(snr_values)))\n",
    "ax4.set_xticklabels(labels, rotation=45, ha=\"right\", fontsize=8)\n",
    "ax4.set_ylabel(\"SNR\")\n",
    "ax4.set_title(\"Signal-to-Noise Ratio\")\n",
    "ax4.axhline(y=QC_THRESHOLDS[\"min_snr\"], color=\"red\", linestyle=\"--\", label=\"Threshold\")\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Performance Matrix\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "perf_data = df_bench[[\"write_time\", \"read_time\"]].values.T\n",
    "im = ax5.imshow(perf_data, cmap=\"RdYlGn_r\", aspect=\"auto\")\n",
    "ax5.set_yticks([0, 1])\n",
    "ax5.set_yticklabels([\"Write\", \"Read\"])\n",
    "ax5.set_xticks(range(len(df_bench)))\n",
    "ax5.set_xticklabels(df_bench[\"config\"], rotation=45, ha=\"right\", fontsize=8)\n",
    "ax5.set_title(\"Performance Heat Map\")\n",
    "for i in range(len(df_bench)):\n",
    "    for j in range(2):\n",
    "        ax5.text(i, j, f\"{perf_data[j, i]:.3f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.colorbar(im, ax=ax5, label=\"Time (s)\")\n",
    "\n",
    "# Plot 6: QC Status Summary\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "qc_status_counts = df_bench[\"qc_status\"].value_counts()\n",
    "colors_pie = [\n",
    "    \"green\" if x == \"PASS\" else \"orange\" if x == \"WARNING\" else \"red\"\n",
    "    for x in qc_status_counts.index\n",
    "]\n",
    "ax6.pie(\n",
    "    qc_status_counts.values,\n",
    "    labels=qc_status_counts.index,\n",
    "    autopct=\"%1.0f%%\",\n",
    "    colors=colors_pie,\n",
    "    startangle=90,\n",
    ")\n",
    "ax6.set_title(\"QC Status Distribution\")\n",
    "\n",
    "# Plot 7: Summary Table\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "ax7.axis(\"off\")\n",
    "\n",
    "summary_text = f\"\"\"INTEGRATED QC + BENCHMARK SUMMARY\n",
    "\n",
    "Dataset: {selected_tomo.name} ({reference_data.shape})\n",
    "Pre-compression QC: {pre_qc_report[\"status\"]}\n",
    "\n",
    "Benchmark Results ({len(df_bench)} configurations tested):\n",
    "\n",
    "{\"Config\":<30} {\"Ratio\":<8} {\"Write(s)\":<10} {\"Read(s)\":<10} {\"SSIM\":<10} {\"QC Status\":<12}\n",
    "{\"-\" * 90}\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df_bench.iterrows():\n",
    "    summary_text += f\"{row['config']:<30} {row['ratio']:<8.3f} {row['write_time']:<10.3f} {row['read_time']:<10.3f} {row['ssim']:<10.6f} {row['qc_status']:<12}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\\n\\nRECOMMENDATION:\n",
    "Best overall: {df_bench.loc[df_bench[\"ratio\"].idxmax(), \"config\"]} (ratio={df_bench[\"ratio\"].max():.3f}Ã—)\n",
    "Fastest: {df_bench.loc[df_bench[\"write_time\"].idxmin(), \"config\"]} (write={df_bench[\"write_time\"].min():.3f}s)\n",
    "All compressions are lossless: {all_identical}\n",
    "\"\"\"\n",
    "\n",
    "ax7.text(\n",
    "    0.05,\n",
    "    0.95,\n",
    "    summary_text,\n",
    "    transform=ax7.transAxes,\n",
    "    fontsize=9,\n",
    "    verticalalignment=\"top\",\n",
    "    family=\"monospace\",\n",
    "    bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.5),\n",
    ")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"CryoET Quality Control + Benchmarking Dashboard\", fontsize=18, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "plt.savefig(OUTPUT_DIR / \"qc_benchmark_dashboard.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Dashboard saved to: {OUTPUT_DIR / 'qc_benchmark_dashboard.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "report-header",
   "metadata": {},
   "source": [
    "## 6. Generate Comprehensive Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive report\n",
    "report = {\n",
    "    \"metadata\": {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"dataset_id\": DATASET_ID,\n",
    "        \"tomogram\": selected_tomo.name,\n",
    "        \"data_shape\": reference_data.shape,\n",
    "        \"download_size_mb\": reference_data.nbytes / (1024**2),\n",
    "    },\n",
    "    \"pre_qc\": pre_qc_report,\n",
    "    \"benchmark_summary\": {\n",
    "        \"configurations_tested\": len(df_bench),\n",
    "        \"all_lossless\": all_identical,\n",
    "        \"all_qc_passed\": (df_bench[\"qc_status\"] == \"PASS\").all(),\n",
    "        \"best_compression\": {\n",
    "            \"config\": df_bench.loc[df_bench[\"ratio\"].idxmax(), \"config\"],\n",
    "            \"ratio\": float(df_bench[\"ratio\"].max()),\n",
    "            \"savings_mb\": float(\n",
    "                pre_qc_report[\"size_mb\"]\n",
    "                - df_bench.loc[df_bench[\"ratio\"].idxmax(), \"size_mb\"]\n",
    "            ),\n",
    "        },\n",
    "        \"fastest\": {\n",
    "            \"config\": df_bench.loc[df_bench[\"write_time\"].idxmin(), \"config\"],\n",
    "            \"write_time\": float(df_bench[\"write_time\"].min()),\n",
    "        },\n",
    "    },\n",
    "    \"post_qc\": qc_results,\n",
    "    \"benchmark_results\": df_bench.to_dict(\"records\"),\n",
    "}\n",
    "\n",
    "# Save comprehensive report\n",
    "report_path = OUTPUT_DIR / \"comprehensive_qc_benchmark_report.json\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE QC + BENCHMARK REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nâœ“ Analysis complete\")\n",
    "print(\"\\nFiles generated:\")\n",
    "print(f\"  - {report_path}\")\n",
    "print(f\"  - {OUTPUT_DIR / 'benchmark_with_qc.csv'}\")\n",
    "print(f\"  - {OUTPUT_DIR / 'qc_original.png'}\")\n",
    "print(f\"  - {OUTPUT_DIR / 'qc_benchmark_dashboard.png'}\")\n",
    "print(\"\\nRecommendations:\")\n",
    "print(\n",
    "    f\"  Best compression: {report['benchmark_summary']['best_compression']['config']}\"\n",
    ")\n",
    "print(\n",
    "    f\"    â†’ Saves {report['benchmark_summary']['best_compression']['savings_mb']:.2f} MB\"\n",
    ")\n",
    "print(f\"  Fastest: {report['benchmark_summary']['fastest']['config']}\")\n",
    "print(f\"    â†’ Write time: {report['benchmark_summary']['fastest']['write_time']:.3f}s\")\n",
    "print(\n",
    "    f\"\\nâœ“ All compressions are lossless: {report['benchmark_summary']['all_lossless']}\"\n",
    ")\n",
    "print(f\"âœ“ All QC checks passed: {report['benchmark_summary']['all_qc_passed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### Extend QC Checks:\n",
    "- Add domain-specific quality metrics\n",
    "- Integrate with PixelPatrol for advanced profiling\n",
    "- Custom outlier detection algorithms\n",
    "\n",
    "### Automate Testing:\n",
    "- Batch process multiple datasets\n",
    "- CI/CD integration for regression testing\n",
    "- Automated alerts for QC failures\n",
    "\n",
    "### Advanced Analysis:\n",
    "- Compare QC metrics across datasets\n",
    "- Machine learning for QC prediction\n",
    "- Correlation analysis: QC â†” compression performance\n",
    "\n",
    "### Resources:\n",
    "- PixelPatrol: https://github.com/ida-mdc/pixel-patrol\n",
    "- CryoET Portal: https://cryoetdataportal.czscience.com/\n",
    "- Zarr Benchmarks: https://github.com/HEFTIEProject/zarr-benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (zarr-benchmarks)",
   "language": "python",
   "name": "zarr-benchmarks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
