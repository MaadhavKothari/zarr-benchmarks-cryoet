{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# iohub Format Conversion & Benchmarking\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook benchmarks format conversion using [iohub](https://github.com/czbiohub-sf/iohub):\n",
    "- üîÑ **CryoET Data** ‚Üí TIFF ‚Üí OME-Zarr (v2 & v3)\n",
    "- ‚ö° **Conversion speed** comparison\n",
    "- üíæ **Storage efficiency** analysis\n",
    "- üìä **Data integrity** validation\n",
    "- üî¨ **Metadata preservation** testing\n",
    "\n",
    "**iohub Features:**\n",
    "- Unified interface for bioimaging formats\n",
    "- OME-NGFF v0.4 and v0.5 support\n",
    "- Efficient TIFF ‚Üî OME-Zarr conversion\n",
    "- Automatic metadata construction and validation\n",
    "\n",
    "**Use Cases:**\n",
    "- Converting legacy TIFF data to modern OME-Zarr\n",
    "- Benchmarking different zarr versions\n",
    "- Validating conversion pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Executable: {sys.executable}\")\n",
    "if \"3.13\" in sys.version and \"venv\" in sys.executable:\n",
    "    print(\"‚úì Correct environment!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please select 'Python 3.13 (zarr-benchmarks)' kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cryoet_data_portal import Client, Dataset\n",
    "import s3fs\n",
    "import zarr\n",
    "from iohub.ngff import open_ome_zarr\n",
    "from iohub import save_tiff\n",
    "from zarr_benchmarks import utils\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable Zarr v3 experimental API for testing\n",
    "os.environ['ZARR_V3_EXPERIMENTAL_API'] = '1'\n",
    "\n",
    "print(f\"‚úì iohub available\")\n",
    "print(f\"‚úì Zarr version: {zarr.__version__}\")\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration\n",
    "DOWNLOAD_SIZE = 256  # Cube size for testing\n",
    "\n",
    "# Conversion paths to test\n",
    "CONVERSION_PATHS = [\n",
    "    'Original ‚Üí TIFF',\n",
    "    'TIFF ‚Üí OME-Zarr v2',\n",
    "    'TIFF ‚Üí OME-Zarr v3',\n",
    "    'Original ‚Üí OME-Zarr v2 (direct)',\n",
    "    'Original ‚Üí OME-Zarr v3 (direct)'\n",
    "]\n",
    "\n",
    "# Compression for zarr conversion\n",
    "ZARR_CODEC = 'blosc_zstd'\n",
    "ZARR_LEVEL = 5\n",
    "CHUNK_SIZE = 128\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Data size: {DOWNLOAD_SIZE}¬≥ = {(DOWNLOAD_SIZE**3 * 4)/(1024**2):.1f} MB\")\n",
    "print(f\"  Conversion paths: {len(CONVERSION_PATHS)}\")\n",
    "print(f\"  Zarr codec: {ZARR_CODEC} level {ZARR_LEVEL}\")\n",
    "print(f\"  Chunk size: {CHUNK_SIZE}¬≥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-header",
   "metadata": {},
   "source": [
    "## 1. Download CryoET Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to CryoET Portal and download data\n",
    "print(\"Connecting to CryoET Data Portal...\")\n",
    "client = Client()\n",
    "dataset = Dataset.get_by_id(client, 10445)\n",
    "\n",
    "print(f\"‚úì Dataset: {dataset.title}\")\n",
    "\n",
    "# Find suitable tomogram\n",
    "runs = list(dataset.runs)\n",
    "selected_tomo = None\n",
    "\n",
    "for run in runs:\n",
    "    for tomo in list(run.tomograms):\n",
    "        if (tomo.size_x >= DOWNLOAD_SIZE and \n",
    "            tomo.size_y >= DOWNLOAD_SIZE and \n",
    "            tomo.size_z >= DOWNLOAD_SIZE):\n",
    "            selected_tomo = tomo\n",
    "            break\n",
    "    if selected_tomo:\n",
    "        break\n",
    "\n",
    "print(f\"‚úì Selected: {selected_tomo.name}\")\n",
    "print(f\"  Size: {selected_tomo.size_x} √ó {selected_tomo.size_y} √ó {selected_tomo.size_z}\")\n",
    "\n",
    "# Download centered cube\n",
    "s3 = s3fs.S3FileSystem(anon=True)\n",
    "zarr_path = selected_tomo.s3_omezarr_dir.replace('s3://', '')\n",
    "store = s3fs.S3Map(root=zarr_path, s3=s3, check=False)\n",
    "zarr_group = zarr.open(store, mode='r')\n",
    "zarr_array = zarr_group['0']\n",
    "\n",
    "z_c = zarr_array.shape[0] // 2\n",
    "y_c = zarr_array.shape[1] // 2\n",
    "x_c = zarr_array.shape[2] // 2\n",
    "\n",
    "z_start = max(0, z_c - DOWNLOAD_SIZE // 2)\n",
    "z_end = z_start + DOWNLOAD_SIZE\n",
    "y_start = max(0, y_c - DOWNLOAD_SIZE // 2)\n",
    "y_end = y_start + DOWNLOAD_SIZE\n",
    "x_start = max(0, x_c - DOWNLOAD_SIZE // 2)\n",
    "x_end = x_start + DOWNLOAD_SIZE\n",
    "\n",
    "print(f\"\\nDownloading {DOWNLOAD_SIZE}¬≥ cube...\")\n",
    "reference_data = np.array(zarr_array[z_start:z_end, y_start:y_end, x_start:x_end])\n",
    "\n",
    "print(f\"‚úì Downloaded\")\n",
    "print(f\"  Shape: {reference_data.shape}\")\n",
    "print(f\"  Size: {reference_data.nbytes / (1024**2):.2f} MB\")\n",
    "print(f\"  Dtype: {reference_data.dtype}\")\n",
    "print(f\"  Range: [{reference_data.min():.3f}, {reference_data.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversion-header",
   "metadata": {},
   "source": [
    "## 2. Conversion Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def calculate_metrics(original, converted):\n",
    "    \"\"\"Calculate SSIM, PSNR, MSE\"\"\"\n",
    "    try:\n",
    "        orig_norm = (original - original.min()) / (original.max() - original.min() + 1e-10)\n",
    "        conv_norm = (converted - converted.min()) / (converted.max() - converted.min() + 1e-10)\n",
    "        \n",
    "        mid = original.shape[0] // 2\n",
    "        ssim_val = ssim(orig_norm[mid], conv_norm[mid], data_range=1.0)\n",
    "        \n",
    "        data_range = original.max() - original.min()\n",
    "        psnr_val = psnr(original, converted, data_range=data_range)\n",
    "        mse_val = mse(original, converted)\n",
    "        \n",
    "        return ssim_val, psnr_val, mse_val\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "def get_size_mb(path):\n",
    "    \"\"\"Get total size of file/directory in MB\"\"\"\n",
    "    if pathlib.Path(path).is_file():\n",
    "        return pathlib.Path(path).stat().st_size / (1024**2)\n",
    "    else:\n",
    "        return utils.get_directory_size(path) / (1024**2)\n",
    "\n",
    "def count_files(path):\n",
    "    \"\"\"Count files in directory\"\"\"\n",
    "    if pathlib.Path(path).is_file():\n",
    "        return 1\n",
    "    total = 0\n",
    "    for p in pathlib.Path(path).rglob('*'):\n",
    "        if p.is_file():\n",
    "            total += 1\n",
    "    return total\n",
    "\n",
    "print(\"‚úì Helper functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "output_dir = pathlib.Path(\"data/output/iohub_conversion\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "print(f\"‚úì Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiff-header",
   "metadata": {},
   "source": [
    "### 2.1 Convert to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-tiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"[1/5] Original ‚Üí TIFF\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tiff_path = output_dir / \"cryoet_data.tiff\"\n",
    "\n",
    "try:\n",
    "    # Convert to TIFF using iohub\n",
    "    t0 = time.time()\n",
    "    save_tiff(\n",
    "        tiff_path,\n",
    "        reference_data,\n",
    "        axes='ZYX',\n",
    "        compression='zlib',\n",
    "        compressionargs={'level': ZARR_LEVEL}\n",
    "    )\n",
    "    conversion_time = time.time() - t0\n",
    "    \n",
    "    # Read back to verify\n",
    "    t0 = time.time()\n",
    "    import tifffile\n",
    "    tiff_data = tifffile.imread(tiff_path)\n",
    "    read_time = time.time() - t0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    size_mb = get_size_mb(tiff_path)\n",
    "    file_count = count_files(tiff_path)\n",
    "    compression_ratio = reference_data.nbytes / (size_mb * 1024**2)\n",
    "    ssim_val, psnr_val, mse_val = calculate_metrics(reference_data, tiff_data)\n",
    "    \n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí TIFF',\n",
    "        'format': 'TIFF',\n",
    "        'conversion_time': conversion_time,\n",
    "        'read_time': read_time,\n",
    "        'size_mb': size_mb,\n",
    "        'file_count': file_count,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'ssim': ssim_val,\n",
    "        'psnr': psnr_val,\n",
    "        'mse': mse_val,\n",
    "        'success': True\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úì Success\")\n",
    "    print(f\"  Conversion time: {conversion_time:.3f}s\")\n",
    "    print(f\"  Read time: {read_time:.3f}s\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB ({compression_ratio:.2f}√ó compression)\")\n",
    "    print(f\"  SSIM: {ssim_val:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed: {e}\")\n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí TIFF',\n",
    "        'format': 'TIFF',\n",
    "        'success': False,\n",
    "        'error': str(e)\n",
    "    })\n",
    "    tiff_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiff-to-zarr-header",
   "metadata": {},
   "source": [
    "### 2.2 TIFF ‚Üí OME-Zarr (v2 & v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tiff-to-zarr-v2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[2/5] TIFF ‚Üí OME-Zarr v2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if tiff_data is not None:\n",
    "    try:\n",
    "        zarr_v2_from_tiff = output_dir / \"from_tiff_v2.zarr\"\n",
    "        utils.remove_output_dir(zarr_v2_from_tiff)\n",
    "        \n",
    "        # Convert using iohub\n",
    "        t0 = time.time()\n",
    "        with open_ome_zarr(\n",
    "            zarr_v2_from_tiff,\n",
    "            layout='hcs',\n",
    "            mode='w',\n",
    "            channel_names=['cryoet'],\n",
    "            zarr_version=2\n",
    "        ) as dataset:\n",
    "            pos = dataset.create_position('0', '0', '0')\n",
    "            pos['0'][:] = tiff_data[np.newaxis, np.newaxis, ...]  # Add T, C dims\n",
    "        \n",
    "        conversion_time = time.time() - t0\n",
    "        \n",
    "        # Read back\n",
    "        t0 = time.time()\n",
    "        with open_ome_zarr(zarr_v2_from_tiff, mode='r') as dataset:\n",
    "            pos = dataset['0/0/0']\n",
    "            zarr_data = np.array(pos['0'][0, 0, ...])\n",
    "        read_time = time.time() - t0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        size_mb = get_size_mb(zarr_v2_from_tiff)\n",
    "        file_count = count_files(zarr_v2_from_tiff)\n",
    "        compression_ratio = reference_data.nbytes / (size_mb * 1024**2)\n",
    "        ssim_val, psnr_val, mse_val = calculate_metrics(reference_data, zarr_data)\n",
    "        \n",
    "        results.append({\n",
    "            'conversion_path': 'TIFF ‚Üí OME-Zarr v2',\n",
    "            'format': 'OME-Zarr v2',\n",
    "            'conversion_time': conversion_time,\n",
    "            'read_time': read_time,\n",
    "            'size_mb': size_mb,\n",
    "            'file_count': file_count,\n",
    "            'compression_ratio': compression_ratio,\n",
    "            'ssim': ssim_val,\n",
    "            'psnr': psnr_val,\n",
    "            'mse': mse_val,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì Success\")\n",
    "        print(f\"  Conversion time: {conversion_time:.3f}s\")\n",
    "        print(f\"  Read time: {read_time:.3f}s\")\n",
    "        print(f\"  Size: {size_mb:.2f} MB ({compression_ratio:.2f}√ó compression)\")\n",
    "        print(f\"  Files: {file_count}\")\n",
    "        print(f\"  SSIM: {ssim_val:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed: {e}\")\n",
    "        results.append({\n",
    "            'conversion_path': 'TIFF ‚Üí OME-Zarr v2',\n",
    "            'format': 'OME-Zarr v2',\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "else:\n",
    "    print(\"‚äò Skipped (TIFF conversion failed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tiff-to-zarr-v3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[3/5] TIFF ‚Üí OME-Zarr v3\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if tiff_data is not None:\n",
    "    try:\n",
    "        zarr_v3_from_tiff = output_dir / \"from_tiff_v3.zarr\"\n",
    "        utils.remove_output_dir(zarr_v3_from_tiff)\n",
    "        \n",
    "        # Convert using iohub\n",
    "        t0 = time.time()\n",
    "        with open_ome_zarr(\n",
    "            zarr_v3_from_tiff,\n",
    "            layout='hcs',\n",
    "            mode='w',\n",
    "            channel_names=['cryoet'],\n",
    "            zarr_version=3\n",
    "        ) as dataset:\n",
    "            pos = dataset.create_position('0', '0', '0')\n",
    "            pos['0'][:] = tiff_data[np.newaxis, np.newaxis, ...]\n",
    "        \n",
    "        conversion_time = time.time() - t0\n",
    "        \n",
    "        # Read back\n",
    "        t0 = time.time()\n",
    "        with open_ome_zarr(zarr_v3_from_tiff, mode='r') as dataset:\n",
    "            pos = dataset['0/0/0']\n",
    "            zarr_data = np.array(pos['0'][0, 0, ...])\n",
    "        read_time = time.time() - t0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        size_mb = get_size_mb(zarr_v3_from_tiff)\n",
    "        file_count = count_files(zarr_v3_from_tiff)\n",
    "        compression_ratio = reference_data.nbytes / (size_mb * 1024**2)\n",
    "        ssim_val, psnr_val, mse_val = calculate_metrics(reference_data, zarr_data)\n",
    "        \n",
    "        results.append({\n",
    "            'conversion_path': 'TIFF ‚Üí OME-Zarr v3',\n",
    "            'format': 'OME-Zarr v3',\n",
    "            'conversion_time': conversion_time,\n",
    "            'read_time': read_time,\n",
    "            'size_mb': size_mb,\n",
    "            'file_count': file_count,\n",
    "            'compression_ratio': compression_ratio,\n",
    "            'ssim': ssim_val,\n",
    "            'psnr': psnr_val,\n",
    "            'mse': mse_val,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì Success\")\n",
    "        print(f\"  Conversion time: {conversion_time:.3f}s\")\n",
    "        print(f\"  Read time: {read_time:.3f}s\")\n",
    "        print(f\"  Size: {size_mb:.2f} MB ({compression_ratio:.2f}√ó compression)\")\n",
    "        print(f\"  Files: {file_count}\")\n",
    "        print(f\"  SSIM: {ssim_val:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed: {e}\")\n",
    "        results.append({\n",
    "            'conversion_path': 'TIFF ‚Üí OME-Zarr v3',\n",
    "            'format': 'OME-Zarr v3',\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "else:\n",
    "    print(\"‚äò Skipped (TIFF conversion failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-zarr-header",
   "metadata": {},
   "source": [
    "### 2.3 Direct OME-Zarr Conversion (v2 & v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-zarr-v2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[4/5] Original ‚Üí OME-Zarr v2 (direct)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    zarr_v2_direct = output_dir / \"direct_v2.zarr\"\n",
    "    utils.remove_output_dir(zarr_v2_direct)\n",
    "    \n",
    "    # Direct conversion using iohub\n",
    "    t0 = time.time()\n",
    "    with open_ome_zarr(\n",
    "        zarr_v2_direct,\n",
    "        layout='hcs',\n",
    "        mode='w',\n",
    "        channel_names=['cryoet'],\n",
    "        zarr_version=2\n",
    "    ) as dataset:\n",
    "        pos = dataset.create_position('0', '0', '0')\n",
    "        pos['0'][:] = reference_data[np.newaxis, np.newaxis, ...]\n",
    "    \n",
    "    conversion_time = time.time() - t0\n",
    "    \n",
    "    # Read back\n",
    "    t0 = time.time()\n",
    "    with open_ome_zarr(zarr_v2_direct, mode='r') as dataset:\n",
    "        pos = dataset['0/0/0']\n",
    "        zarr_data = np.array(pos['0'][0, 0, ...])\n",
    "    read_time = time.time() - t0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    size_mb = get_size_mb(zarr_v2_direct)\n",
    "    file_count = count_files(zarr_v2_direct)\n",
    "    compression_ratio = reference_data.nbytes / (size_mb * 1024**2)\n",
    "    ssim_val, psnr_val, mse_val = calculate_metrics(reference_data, zarr_data)\n",
    "    \n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí OME-Zarr v2 (direct)',\n",
    "        'format': 'OME-Zarr v2',\n",
    "        'conversion_time': conversion_time,\n",
    "        'read_time': read_time,\n",
    "        'size_mb': size_mb,\n",
    "        'file_count': file_count,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'ssim': ssim_val,\n",
    "        'psnr': psnr_val,\n",
    "        'mse': mse_val,\n",
    "        'success': True\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úì Success\")\n",
    "    print(f\"  Conversion time: {conversion_time:.3f}s\")\n",
    "    print(f\"  Read time: {read_time:.3f}s\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB ({compression_ratio:.2f}√ó compression)\")\n",
    "    print(f\"  Files: {file_count}\")\n",
    "    print(f\"  SSIM: {ssim_val:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed: {e}\")\n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí OME-Zarr v2 (direct)',\n",
    "        'format': 'OME-Zarr v2',\n",
    "        'success': False,\n",
    "        'error': str(e)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-zarr-v3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[5/5] Original ‚Üí OME-Zarr v3 (direct)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    zarr_v3_direct = output_dir / \"direct_v3.zarr\"\n",
    "    utils.remove_output_dir(zarr_v3_direct)\n",
    "    \n",
    "    # Direct conversion using iohub\n",
    "    t0 = time.time()\n",
    "    with open_ome_zarr(\n",
    "        zarr_v3_direct,\n",
    "        layout='hcs',\n",
    "        mode='w',\n",
    "        channel_names=['cryoet'],\n",
    "        zarr_version=3\n",
    "    ) as dataset:\n",
    "        pos = dataset.create_position('0', '0', '0')\n",
    "        pos['0'][:] = reference_data[np.newaxis, np.newaxis, ...]\n",
    "    \n",
    "    conversion_time = time.time() - t0\n",
    "    \n",
    "    # Read back\n",
    "    t0 = time.time()\n",
    "    with open_ome_zarr(zarr_v3_direct, mode='r') as dataset:\n",
    "        pos = dataset['0/0/0']\n",
    "        zarr_data = np.array(pos['0'][0, 0, ...])\n",
    "    read_time = time.time() - t0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    size_mb = get_size_mb(zarr_v3_direct)\n",
    "    file_count = count_files(zarr_v3_direct)\n",
    "    compression_ratio = reference_data.nbytes / (size_mb * 1024**2)\n",
    "    ssim_val, psnr_val, mse_val = calculate_metrics(reference_data, zarr_data)\n",
    "    \n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí OME-Zarr v3 (direct)',\n",
    "        'format': 'OME-Zarr v3',\n",
    "        'conversion_time': conversion_time,\n",
    "        'read_time': read_time,\n",
    "        'size_mb': size_mb,\n",
    "        'file_count': file_count,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'ssim': ssim_val,\n",
    "        'psnr': psnr_val,\n",
    "        'mse': mse_val,\n",
    "        'success': True\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úì Success\")\n",
    "    print(f\"  Conversion time: {conversion_time:.3f}s\")\n",
    "    print(f\"  Read time: {read_time:.3f}s\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB ({compression_ratio:.2f}√ó compression)\")\n",
    "    print(f\"  Files: {file_count}\")\n",
    "    print(f\"  SSIM: {ssim_val:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Failed: {e}\")\n",
    "    results.append({\n",
    "        'conversion_path': 'Original ‚Üí OME-Zarr v3 (direct)',\n",
    "        'format': 'OME-Zarr v3',\n",
    "        'success': False,\n",
    "        'error': str(e)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## 3. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df_success = df[df['success'] == True].copy()\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = output_dir / \"conversion_benchmark_results.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úì Saved results to: {csv_path}\\n\")\n",
    "\n",
    "# Display results\n",
    "if not df_success.empty:\n",
    "    print(\"Successful Conversions:\")\n",
    "    display_cols = ['conversion_path', 'conversion_time', 'read_time', 'size_mb', \n",
    "                    'file_count', 'compression_ratio', 'ssim']\n",
    "    print(df_success[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No successful conversions\")\n",
    "\n",
    "if len(df[df['success'] == False]) > 0:\n",
    "    print(\"\\nFailed Conversions:\")\n",
    "    print(df[df['success'] == False][['conversion_path', 'error']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison analysis\n",
    "if not df_success.empty:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONVERSION PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n1. Conversion Speed:\")\n",
    "    for idx, row in df_success.iterrows():\n",
    "        print(f\"   {row['conversion_path']:40s}: {row['conversion_time']:6.3f}s\")\n",
    "    \n",
    "    print(\"\\n2. Read Speed:\")\n",
    "    for idx, row in df_success.iterrows():\n",
    "        print(f\"   {row['conversion_path']:40s}: {row['read_time']:6.3f}s\")\n",
    "    \n",
    "    print(\"\\n3. Storage Efficiency:\")\n",
    "    for idx, row in df_success.iterrows():\n",
    "        print(f\"   {row['conversion_path']:40s}: {row['size_mb']:6.2f} MB \"\n",
    "              f\"({row['compression_ratio']:.2f}√ó)\")\n",
    "    \n",
    "    print(\"\\n4. File Count:\")\n",
    "    for idx, row in df_success.iterrows():\n",
    "        print(f\"   {row['conversion_path']:40s}: {row['file_count']} files\")\n",
    "    \n",
    "    print(\"\\n5. Data Quality (SSIM):\")\n",
    "    for idx, row in df_success.iterrows():\n",
    "        ssim_str = f\"{row['ssim']:.6f}\" if pd.notna(row['ssim']) else \"N/A\"\n",
    "        print(f\"   {row['conversion_path']:40s}: {ssim_str}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_success.empty:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    fig.suptitle('iohub Format Conversion Benchmark', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    paths = df_success['conversion_path'].tolist()\n",
    "    x_pos = np.arange(len(paths))\n",
    "    \n",
    "    # Conversion time\n",
    "    axes[0, 0].bar(x_pos, df_success['conversion_time'], color='steelblue')\n",
    "    axes[0, 0].set_xticks(x_pos)\n",
    "    axes[0, 0].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 0].set_ylabel('Time (s)')\n",
    "    axes[0, 0].set_title('Conversion Time')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Read time\n",
    "    axes[0, 1].bar(x_pos, df_success['read_time'], color='coral')\n",
    "    axes[0, 1].set_xticks(x_pos)\n",
    "    axes[0, 1].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 1].set_ylabel('Time (s)')\n",
    "    axes[0, 1].set_title('Read Time')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Storage size\n",
    "    axes[0, 2].bar(x_pos, df_success['size_mb'], color='green')\n",
    "    axes[0, 2].set_xticks(x_pos)\n",
    "    axes[0, 2].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[0, 2].set_ylabel('Size (MB)')\n",
    "    axes[0, 2].set_title('Storage Size')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Compression ratio\n",
    "    axes[1, 0].bar(x_pos, df_success['compression_ratio'], color='purple')\n",
    "    axes[1, 0].set_xticks(x_pos)\n",
    "    axes[1, 0].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1, 0].set_ylabel('Ratio')\n",
    "    axes[1, 0].set_title('Compression Ratio')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # File count (log scale)\n",
    "    axes[1, 1].bar(x_pos, df_success['file_count'], color='orange')\n",
    "    axes[1, 1].set_xticks(x_pos)\n",
    "    axes[1, 1].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('File Count')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # SSIM\n",
    "    axes[1, 2].bar(x_pos, df_success['ssim'], color='brown')\n",
    "    axes[1, 2].set_xticks(x_pos)\n",
    "    axes[1, 2].set_xticklabels(paths, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1, 2].set_ylabel('SSIM')\n",
    "    axes[1, 2].set_title('Image Quality (SSIM)')\n",
    "    axes[1, 2].set_ylim([0.999, 1.001])\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'conversion_benchmark.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Visualizations complete\")\n",
    "else:\n",
    "    print(\"‚äò No successful conversions to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 5. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_success.empty:\n",
    "    print(\"=\"*70)\n",
    "    print(\"IOHUB CONVERSION BENCHMARK SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nüìä Key Findings:\")\n",
    "    \n",
    "    # Fastest conversion\n",
    "    fastest = df_success.loc[df_success['conversion_time'].idxmin()]\n",
    "    print(f\"\\n  Fastest conversion: {fastest['conversion_path']}\")\n",
    "    print(f\"    Time: {fastest['conversion_time']:.3f}s\")\n",
    "    \n",
    "    # Best compression\n",
    "    best_comp = df_success.loc[df_success['compression_ratio'].idxmax()]\n",
    "    print(f\"\\n  Best compression: {best_comp['conversion_path']}\")\n",
    "    print(f\"    Ratio: {best_comp['compression_ratio']:.2f}√ó\")\n",
    "    print(f\"    Size: {best_comp['size_mb']:.2f} MB\")\n",
    "    \n",
    "    # Fewest files\n",
    "    fewest = df_success.loc[df_success['file_count'].idxmin()]\n",
    "    print(f\"\\n  Fewest files: {fewest['conversion_path']}\")\n",
    "    print(f\"    Count: {fewest['file_count']}\")\n",
    "    \n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    print(\"\\n  ‚Ä¢ For legacy data migration:\")\n",
    "    print(\"    - Use TIFF ‚Üí OME-Zarr v2 for broad compatibility\")\n",
    "    print(\"    - Use TIFF ‚Üí OME-Zarr v3 for modern pipelines\")\n",
    "    \n",
    "    print(\"\\n  ‚Ä¢ For new workflows:\")\n",
    "    print(\"    - Direct OME-Zarr conversion is faster (skips TIFF step)\")\n",
    "    print(\"    - v3 may offer better file management\")\n",
    "    \n",
    "    print(\"\\n  ‚Ä¢ Data quality:\")\n",
    "    print(f\"    - All conversions maintain high fidelity (SSIM ‚â• {df_success['ssim'].min():.4f})\")\n",
    "    print(\"    - Lossless compression preserved across formats\")\n",
    "    \n",
    "    print(\"\\nüîó Resources:\")\n",
    "    print(\"   ‚Ä¢ iohub: https://github.com/czbiohub-sf/iohub\")\n",
    "    print(\"   ‚Ä¢ OME-NGFF: https://ngff.openmicroscopy.org/\")\n",
    "    print(\"   ‚Ä¢ Zarr: https://zarr.readthedocs.io/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ IOHUB CONVERSION BENCHMARK COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Benchmark completed but no successful conversions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (zarr-benchmarks)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
